# fasttext-on-yelp-dataset

## Overview
This Jupyter notebook explores the use of FastText models on the Yelp dataset for text analysis. It includes text preprocessing steps, loading pre-trained FastText word embeddings, and training a FastText model using the Yelp dataset.

## Requirements
- Python 3.10
- Libraries: NumPy, Pandas, NLTK, Gensim

## Instructions
1. Clone the repository or download the notebook file.
2. Ensure you have the necessary Python libraries installed.
3. Open the notebook in a Jupyter environment.
4. Run each cell in the notebook sequentially to execute the code blocks.
5. Follow the instructions within the notebook for downloading pre-trained models and packages.

## Contents
- **Importing Libraries**: Imports necessary libraries for text preprocessing and model training.
- **Downloading pre-trained FastText model**: Downloads pre-trained FastText word embeddings for English.
- **Downloading needed packages for Text Preprocessing**: Downloads NLTK resources for text preprocessing.
- **Downloading English stopping words**: Creates a set of English stopwords.
- **Extracting Text data from Yelp dataset**: Reads Yelp dataset and prepares text data for analysis.
- **Defining a lemmatizer object to be used later**: Defines a WordNetLemmatizer object.
- **Function for Text Preprocessing**: Defines a text preprocessing function for cleaning and preparing text data.

## Notes
- This notebook is designed for educational purposes to demonstrate text analysis techniques using FastText on the Yelp dataset.
- Make sure to adjust paths and configurations as needed based on your environment.
